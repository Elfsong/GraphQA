{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from graph_qa_dataset import GraphQADataset\n",
    "from torch_geometric.loader import DataListLoader\n",
    "from model.graph_qa_model import GAT, HGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/mingzhe/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc95588117d0436788d1547804642961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-10-31 02:25:53 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb03ebc4bb649c6a9a299ba64f57aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 02:25:54 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-10-31 02:25:54 INFO: Use device: gpu\n",
      "2022-10-31 02:25:54 INFO: Loading: tokenize\n",
      "2022-10-31 02:25:56 INFO: Loading: pos\n",
      "2022-10-31 02:25:56 INFO: Loading: constituency\n",
      "2022-10-31 02:25:57 INFO: Done loading processors!\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.29s/it]\n",
      "Found cached dataset squad (/home/mingzhe/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681ed7e8ef6846b4857df050eb4ebaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-10-31 02:26:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb9d216569b4a5094d2b213140d5da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 02:26:33 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-10-31 02:26:33 INFO: Use device: gpu\n",
      "2022-10-31 02:26:33 INFO: Loading: tokenize\n",
      "2022-10-31 02:26:33 INFO: Loading: pos\n",
      "2022-10-31 02:26:33 INFO: Loading: constituency\n",
      "2022-10-31 02:26:33 INFO: Done loading processors!\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GraphQADataset(split=\"train\", data_size=2)\n",
    "val_dataset = GraphQADataset(split=\"validation\", data_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataListLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataListLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGT(hidden_channels=64, out_channels=2, num_heads=4, num_layers=2, metadata=train_dataset.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mquestion\u001b[0m={\n",
      "    x=[27, 768],\n",
      "    y=[27]\n",
      "  },\n",
      "  \u001b[1mcontext\u001b[0m={\n",
      "    x=[260, 768],\n",
      "    y=[260]\n",
      "  },\n",
      "  \u001b[1m(question, connect, question)\u001b[0m={ edge_index=[2, 26] },\n",
      "  \u001b[1m(context, connect, question)\u001b[0m={ edge_index=[2, 7] },\n",
      "  \u001b[1m(context, connect, context)\u001b[0m={ edge_index=[2, 253] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "data = train_dataset.graph_data[0][0]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0779, -0.0435],\n",
       "        [ 0.0780, -0.0439],\n",
       "        [ 0.0767, -0.0472],\n",
       "        [ 0.0724, -0.0433],\n",
       "        [ 0.0734, -0.0420],\n",
       "        [ 0.0741, -0.0397],\n",
       "        [ 0.0642, -0.0435],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0632, -0.0440],\n",
       "        [ 0.0714, -0.0461],\n",
       "        [ 0.0626, -0.0442],\n",
       "        [ 0.0685, -0.0486],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0700, -0.0421],\n",
       "        [ 0.0655, -0.0436],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0736, -0.0483],\n",
       "        [ 0.0763, -0.0461],\n",
       "        [ 0.0760, -0.0482],\n",
       "        [ 0.0698, -0.0475],\n",
       "        [ 0.0657, -0.0412],\n",
       "        [ 0.0696, -0.0459],\n",
       "        [ 0.0654, -0.0447],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0674, -0.0417],\n",
       "        [ 0.0673, -0.0434],\n",
       "        [ 0.0623, -0.0470],\n",
       "        [ 0.0691, -0.0436],\n",
       "        [ 0.0630, -0.0427],\n",
       "        [ 0.0678, -0.0440],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0782, -0.0520],\n",
       "        [ 0.0649, -0.0498],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0657, -0.0409],\n",
       "        [ 0.0659, -0.0427],\n",
       "        [ 0.0783, -0.0521],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0772, -0.0527],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0642, -0.0431],\n",
       "        [ 0.0644, -0.0425],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0736, -0.0477],\n",
       "        [ 0.0758, -0.0446],\n",
       "        [ 0.0755, -0.0478],\n",
       "        [ 0.0718, -0.0468],\n",
       "        [ 0.0690, -0.0463],\n",
       "        [ 0.0654, -0.0453],\n",
       "        [ 0.0631, -0.0430],\n",
       "        [ 0.0640, -0.0425],\n",
       "        [ 0.0723, -0.0445],\n",
       "        [ 0.0672, -0.0458],\n",
       "        [ 0.0645, -0.0448],\n",
       "        [ 0.0667, -0.0446],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0685, -0.0450],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0674, -0.0417],\n",
       "        [ 0.0673, -0.0434],\n",
       "        [ 0.0663, -0.0446],\n",
       "        [ 0.0765, -0.0465],\n",
       "        [ 0.0760, -0.0471],\n",
       "        [ 0.0602, -0.0435],\n",
       "        [ 0.0703, -0.0427],\n",
       "        [ 0.0679, -0.0414],\n",
       "        [ 0.0704, -0.0429],\n",
       "        [ 0.0678, -0.0440],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0765, -0.0484],\n",
       "        [ 0.0696, -0.0506],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0640, -0.0437],\n",
       "        [ 0.0659, -0.0427],\n",
       "        [ 0.0715, -0.0479],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0703, -0.0461],\n",
       "        [ 0.0675, -0.0439],\n",
       "        [ 0.0731, -0.0482],\n",
       "        [ 0.0615, -0.0436],\n",
       "        [ 0.0739, -0.0480],\n",
       "        [ 0.0677, -0.0469],\n",
       "        [ 0.0649, -0.0455],\n",
       "        [ 0.0720, -0.0526],\n",
       "        [ 0.0680, -0.0474],\n",
       "        [ 0.0717, -0.0477],\n",
       "        [ 0.0615, -0.0436],\n",
       "        [ 0.0705, -0.0469],\n",
       "        [ 0.0632, -0.0464],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0692, -0.0412],\n",
       "        [ 0.0699, -0.0524],\n",
       "        [ 0.0628, -0.0437],\n",
       "        [ 0.0663, -0.0430],\n",
       "        [ 0.0672, -0.0456],\n",
       "        [ 0.0646, -0.0434],\n",
       "        [ 0.0717, -0.0429],\n",
       "        [ 0.0628, -0.0437],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0706, -0.0472],\n",
       "        [ 0.0735, -0.0458],\n",
       "        [ 0.0726, -0.0480],\n",
       "        [ 0.0702, -0.0451],\n",
       "        [ 0.0663, -0.0448],\n",
       "        [ 0.0670, -0.0461],\n",
       "        [ 0.0686, -0.0415],\n",
       "        [ 0.0685, -0.0450],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0674, -0.0417],\n",
       "        [ 0.0673, -0.0434],\n",
       "        [ 0.0678, -0.0440],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0717, -0.0467],\n",
       "        [ 0.0632, -0.0484],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0645, -0.0431],\n",
       "        [ 0.0712, -0.0441],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0686, -0.0443],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0652, -0.0420],\n",
       "        [ 0.0695, -0.0425],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0717, -0.0477],\n",
       "        [ 0.0749, -0.0463],\n",
       "        [ 0.0741, -0.0480],\n",
       "        [ 0.0676, -0.0452],\n",
       "        [ 0.0654, -0.0453],\n",
       "        [ 0.0631, -0.0430],\n",
       "        [ 0.0605, -0.0428],\n",
       "        [ 0.0632, -0.0484],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0645, -0.0431],\n",
       "        [ 0.0678, -0.0440],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0728, -0.0497],\n",
       "        [ 0.0711, -0.0480],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0702, -0.0456],\n",
       "        [ 0.0704, -0.0429],\n",
       "        [ 0.0742, -0.0470],\n",
       "        [ 0.0674, -0.0466],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0675, -0.0402],\n",
       "        [ 0.0660, -0.0417],\n",
       "        [ 0.0743, -0.0500],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0750, -0.0506],\n",
       "        [ 0.0641, -0.0456],\n",
       "        [ 0.0663, -0.0446],\n",
       "        [ 0.0645, -0.0426],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0739, -0.0458],\n",
       "        [ 0.0779, -0.0418],\n",
       "        [ 0.0765, -0.0455],\n",
       "        [ 0.0703, -0.0427],\n",
       "        [ 0.0679, -0.0414],\n",
       "        [ 0.0767, -0.0497],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0768, -0.0483],\n",
       "        [ 0.0632, -0.0480],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0623, -0.0433],\n",
       "        [ 0.0765, -0.0476],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0764, -0.0465],\n",
       "        [ 0.0742, -0.0478],\n",
       "        [ 0.0711, -0.0480],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0702, -0.0456],\n",
       "        [ 0.0700, -0.0479],\n",
       "        [ 0.0622, -0.0430],\n",
       "        [ 0.0715, -0.0485],\n",
       "        [ 0.0696, -0.0442],\n",
       "        [ 0.0668, -0.0422],\n",
       "        [ 0.0704, -0.0429],\n",
       "        [ 0.0707, -0.0463],\n",
       "        [ 0.0685, -0.0435],\n",
       "        [ 0.0715, -0.0464],\n",
       "        [ 0.0671, -0.0436],\n",
       "        [ 0.0650, -0.0419],\n",
       "        [ 0.0697, -0.0476],\n",
       "        [ 0.0772, -0.0527],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0642, -0.0431],\n",
       "        [ 0.0644, -0.0425],\n",
       "        [ 0.0694, -0.0460],\n",
       "        [ 0.0679, -0.0434],\n",
       "        [ 0.0749, -0.0456],\n",
       "        [ 0.0712, -0.0406],\n",
       "        [ 0.0746, -0.0496],\n",
       "        [ 0.0686, -0.0415],\n",
       "        [ 0.0749, -0.0479],\n",
       "        [ 0.0650, -0.0422],\n",
       "        [ 0.0688, -0.0437],\n",
       "        [ 0.0696, -0.0419],\n",
       "        [ 0.0678, -0.0418],\n",
       "        [ 0.0640, -0.0425],\n",
       "        [ 0.0687, -0.0423],\n",
       "        [ 0.0685, -0.0413],\n",
       "        [ 0.0728, -0.0459],\n",
       "        [ 0.0724, -0.0503],\n",
       "        [ 0.0760, -0.0462],\n",
       "        [ 0.0748, -0.0500],\n",
       "        [ 0.0713, -0.0473],\n",
       "        [ 0.0672, -0.0472],\n",
       "        [ 0.0622, -0.0430],\n",
       "        [ 0.0686, -0.0441],\n",
       "        [ 0.0688, -0.0457],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0719, -0.0434],\n",
       "        [ 0.0658, -0.0469],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0646, -0.0479],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0674, -0.0417],\n",
       "        [ 0.0642, -0.0449],\n",
       "        [ 0.0630, -0.0454],\n",
       "        [ 0.0663, -0.0446],\n",
       "        [ 0.0720, -0.0484],\n",
       "        [ 0.0640, -0.0425],\n",
       "        [ 0.0738, -0.0459],\n",
       "        [ 0.0665, -0.0504],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0668, -0.0431],\n",
       "        [ 0.0678, -0.0424],\n",
       "        [ 0.0721, -0.0489],\n",
       "        [ 0.0720, -0.0464],\n",
       "        [ 0.0695, -0.0435],\n",
       "        [ 0.0736, -0.0474],\n",
       "        [ 0.0742, -0.0472],\n",
       "        [ 0.0637, -0.0428],\n",
       "        [ 0.0703, -0.0502],\n",
       "        [ 0.0643, -0.0443],\n",
       "        [ 0.0739, -0.0486],\n",
       "        [ 0.0687, -0.0478],\n",
       "        [ 0.0665, -0.0440],\n",
       "        [ 0.0652, -0.0438],\n",
       "        [ 0.0663, -0.0446],\n",
       "        [ 0.0638, -0.0476],\n",
       "        [ 0.0602, -0.0428],\n",
       "        [ 0.0691, -0.0436],\n",
       "        [ 0.0630, -0.0427],\n",
       "        [ 0.0642, -0.0465],\n",
       "        [ 0.0704, -0.0429],\n",
       "        [ 0.0678, -0.0440],\n",
       "        [ 0.0657, -0.0430],\n",
       "        [ 0.0793, -0.0495],\n",
       "        [ 0.0753, -0.0528],\n",
       "        [ 0.0652, -0.0442],\n",
       "        [ 0.0612, -0.0447],\n",
       "        [ 0.0704, -0.0429],\n",
       "        [ 0.0674, -0.0410],\n",
       "        [ 0.0644, -0.0428],\n",
       "        [ 0.0659, -0.0427],\n",
       "        [ 0.0706, -0.0461],\n",
       "        [ 0.0642, -0.0427],\n",
       "        [ 0.0667, -0.0441],\n",
       "        [ 0.0644, -0.0425],\n",
       "        [ 0.0728, -0.0459]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': tensor([[-0.8143, -0.4067, -0.5450,  ..., -0.4847, -0.6654,  0.7649],\n",
       "         [-0.8143, -0.4067, -0.5450,  ..., -0.4847, -0.6654,  0.7649],\n",
       "         [-0.8143, -0.4067, -0.5450,  ..., -0.4847, -0.6654,  0.7649],\n",
       "         ...,\n",
       "         [-0.8603, -0.3164, -0.0064,  ...,  0.2306, -0.6456,  0.8738],\n",
       "         [-0.9448, -0.4524, -0.2776,  ..., -0.2155, -0.6419,  0.9170],\n",
       "         [-0.9547, -0.4047, -0.8256,  ..., -0.6352, -0.7834,  0.9697]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " 'context': tensor([[-0.8902, -0.2453, -0.8936,  ..., -0.8152, -0.5622,  0.8019],\n",
       "         [-0.8902, -0.2453, -0.8936,  ..., -0.8152, -0.5622,  0.8019],\n",
       "         [-0.8902, -0.2453, -0.8936,  ..., -0.8152, -0.5622,  0.8019],\n",
       "         ...,\n",
       "         [-0.7895, -0.2154,  0.4098,  ...,  0.4250, -0.6165,  0.8128],\n",
       "         [-0.7895, -0.2154,  0.4098,  ...,  0.4250, -0.6165,  0.8128],\n",
       "         [-0.9174, -0.3771, -0.8672,  ..., -0.6802, -0.7260,  0.9148]],\n",
       "        grad_fn=<StackBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('question',\n",
       "  'connect',\n",
       "  'question'): tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 21, 22, 23, 24, 25, 26],\n",
       "         [ 0,  1,  2,  3,  3,  5,  2,  7,  7,  9,  9,  9,  7, 13,  7, 15, 15, 17,\n",
       "          17, 19, 15, 21, 21, 23, 23,  2]]),\n",
       " ('context',\n",
       "  'connect',\n",
       "  'question'): tensor([[0, 1, 2, 3, 4, 5, 6],\n",
       "         [0, 0, 0, 0, 0, 0, 0]]),\n",
       " ('context',\n",
       "  'connect',\n",
       "  'context'): tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "           15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "           30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  44,\n",
       "           45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "           59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
       "           73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
       "           87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98, 100, 101,\n",
       "          102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "          116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130,\n",
       "          131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "          145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159,\n",
       "          160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "          174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
       "          188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202,\n",
       "          203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
       "          217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
       "          231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "          245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258,\n",
       "          259],\n",
       "         [  0,   1,   2,   3,   2,   2,   6,   6,   2,   9,   9,  11,  11,  11,\n",
       "            2,   1,  17,  18,  19,  19,  21,  22,  22,  22,  22,  21,  21,  18,\n",
       "           29,  18,  31,  32,  32,  32,  31,  36,  36,  38,  38,  38,  18,   2,\n",
       "           44,  45,  46,  47,  48,  47,  47,  51,  52,  51,  54,  54,  56,  56,\n",
       "           56,  46,  46,  61,  62,  62,  64,  45,  45,  67,  45,  69,  70,  70,\n",
       "           70,  69,  74,  74,  76,  69,  78,  78,  80,  81,  80,  83,  83,  85,\n",
       "           85,  87,  88,  88,  87,  91,  91,  91,  91,  91,  45,  45,   3, 100,\n",
       "          101, 102, 102, 104, 104, 106, 106, 106, 101, 110, 101, 112, 113, 113,\n",
       "          112, 116, 116, 118, 118, 118, 101,   4, 124, 125, 126, 127, 126, 126,\n",
       "          130, 130, 125, 133, 125, 135, 136, 136, 135, 135, 140, 141, 141, 141,\n",
       "          140, 145, 145, 147, 147, 147, 125,   5, 153, 154, 155, 154, 157, 157,\n",
       "          159, 160, 160, 159, 163, 163, 165, 166, 167, 167, 166, 170, 170, 172,\n",
       "          173, 172, 172, 176, 165, 178, 179, 178, 181, 182, 182, 182, 181, 186,\n",
       "          181, 188, 188, 190, 190, 192, 192, 192, 188, 196, 196, 198, 154,   6,\n",
       "          202, 203, 204, 205, 205, 207, 208, 208, 207, 211, 211, 213, 213, 213,\n",
       "          204, 204, 204, 219, 219, 221, 222, 222, 222, 221, 226, 227, 226, 229,\n",
       "          230, 230, 232, 232, 234, 235, 235, 234, 234, 239, 239, 239, 204, 204,\n",
       "          203, 245, 203, 247, 248, 248, 248, 248, 248, 248, 247, 255, 255, 257,\n",
       "          203]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('syntax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86a73a47477ba0aeb5784a0601a09572162e340e9fb1f4748688670acf6653e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
