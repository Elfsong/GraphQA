{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from graph_qa_dataset import GraphQADataset\n",
    "from torch_geometric.loader import DataListLoader\n",
    "from model.graph_qa_model import GAT, HGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/mingzhe/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f882d7540fe04b839119830e23bf4818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-10-31 03:45:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a0fe4518cc4c0680a526b53bd1adb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 03:45:15 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-10-31 03:45:15 INFO: Use device: gpu\n",
      "2022-10-31 03:45:15 INFO: Loading: tokenize\n",
      "2022-10-31 03:45:15 INFO: Loading: pos\n",
      "2022-10-31 03:45:16 INFO: Loading: constituency\n",
      "2022-10-31 03:45:16 INFO: Done loading processors!\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_dataset = GraphQADataset(split=\"train\", data_size=20)\n",
    "val_dataset = GraphQADataset(split=\"validation\", data_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGT(hidden_channels=64, out_channels=2, num_heads=4, num_layers=2, metadata=train_dataset.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mquestion\u001b[0m={\n",
      "    x=[27, 768],\n",
      "    y=[27, 2]\n",
      "  },\n",
      "  \u001b[1mcontext\u001b[0m={\n",
      "    x=[260, 768],\n",
      "    y=[260, 2]\n",
      "  },\n",
      "  \u001b[1m(question, connect, question)\u001b[0m={ edge_index=[2, 52] },\n",
      "  \u001b[1m(context, connect, question)\u001b[0m={ edge_index=[2, 7] },\n",
      "  \u001b[1m(context, connect, context)\u001b[0m={ edge_index=[2, 506] },\n",
      "  \u001b[1m(question, rev_connect, context)\u001b[0m={ edge_index=[2, 7] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "data = train_dataset.graph_data[0][0]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0244, 0.0301],\n",
       "        [0.0250, 0.0308],\n",
       "        [0.0257, 0.0297],\n",
       "        [0.0246, 0.0275],\n",
       "        [0.0240, 0.0281],\n",
       "        [0.0266, 0.0231],\n",
       "        [0.0218, 0.0247],\n",
       "        [0.0172, 0.0301],\n",
       "        [0.0180, 0.0308],\n",
       "        [0.0242, 0.0345],\n",
       "        [0.0177, 0.0371],\n",
       "        [0.0224, 0.0385],\n",
       "        [0.0219, 0.0326],\n",
       "        [0.0291, 0.0323],\n",
       "        [0.0232, 0.0324],\n",
       "        [0.0160, 0.0370],\n",
       "        [0.0150, 0.0200],\n",
       "        [0.0192, 0.0420],\n",
       "        [0.0218, 0.0407],\n",
       "        [0.0213, 0.0406],\n",
       "        [0.0229, 0.0344],\n",
       "        [0.0259, 0.0378],\n",
       "        [0.0211, 0.0359],\n",
       "        [0.0204, 0.0328],\n",
       "        [0.0242, 0.0334],\n",
       "        [0.0258, 0.0347],\n",
       "        [0.0195, 0.0334],\n",
       "        [0.0262, 0.0353],\n",
       "        [0.0205, 0.0343],\n",
       "        [0.0186, 0.0363],\n",
       "        [0.0200, 0.0332],\n",
       "        [0.0220, 0.0401],\n",
       "        [0.0179, 0.0359],\n",
       "        [0.0218, 0.0322],\n",
       "        [0.0240, 0.0330],\n",
       "        [0.0244, 0.0335],\n",
       "        [0.0243, 0.0370],\n",
       "        [0.0157, 0.0366],\n",
       "        [0.0249, 0.0374],\n",
       "        [0.0167, 0.0368],\n",
       "        [0.0178, 0.0376],\n",
       "        [0.0186, 0.0378],\n",
       "        [0.0172, 0.0401],\n",
       "        [0.0179, 0.0179],\n",
       "        [0.0232, 0.0378],\n",
       "        [0.0247, 0.0370],\n",
       "        [0.0248, 0.0359],\n",
       "        [0.0222, 0.0367],\n",
       "        [0.0202, 0.0332],\n",
       "        [0.0193, 0.0342],\n",
       "        [0.0227, 0.0316],\n",
       "        [0.0257, 0.0350],\n",
       "        [0.0188, 0.0366],\n",
       "        [0.0197, 0.0347],\n",
       "        [0.0213, 0.0363],\n",
       "        [0.0207, 0.0323],\n",
       "        [0.0251, 0.0360],\n",
       "        [0.0199, 0.0339],\n",
       "        [0.0237, 0.0345],\n",
       "        [0.0253, 0.0358],\n",
       "        [0.0219, 0.0350],\n",
       "        [0.0267, 0.0364],\n",
       "        [0.0270, 0.0344],\n",
       "        [0.0205, 0.0336],\n",
       "        [0.0221, 0.0346],\n",
       "        [0.0212, 0.0337],\n",
       "        [0.0229, 0.0345],\n",
       "        [0.0195, 0.0344],\n",
       "        [0.0200, 0.0333],\n",
       "        [0.0243, 0.0380],\n",
       "        [0.0213, 0.0363],\n",
       "        [0.0229, 0.0316],\n",
       "        [0.0244, 0.0323],\n",
       "        [0.0255, 0.0329],\n",
       "        [0.0243, 0.0343],\n",
       "        [0.0190, 0.0354],\n",
       "        [0.0211, 0.0366],\n",
       "        [0.0216, 0.0366],\n",
       "        [0.0256, 0.0338],\n",
       "        [0.0189, 0.0326],\n",
       "        [0.0263, 0.0360],\n",
       "        [0.0203, 0.0350],\n",
       "        [0.0199, 0.0357],\n",
       "        [0.0219, 0.0387],\n",
       "        [0.0303, 0.0300],\n",
       "        [0.0245, 0.0342],\n",
       "        [0.0220, 0.0297],\n",
       "        [0.0195, 0.0342],\n",
       "        [0.0202, 0.0326],\n",
       "        [0.0202, 0.0328],\n",
       "        [0.0252, 0.0314],\n",
       "        [0.0191, 0.0384],\n",
       "        [0.0230, 0.0313],\n",
       "        [0.0255, 0.0308],\n",
       "        [0.0253, 0.0320],\n",
       "        [0.0219, 0.0312],\n",
       "        [0.0281, 0.0327],\n",
       "        [0.0195, 0.0347],\n",
       "        [0.0190, 0.0362],\n",
       "        [0.0178, 0.0181],\n",
       "        [0.0228, 0.0382],\n",
       "        [0.0245, 0.0385],\n",
       "        [0.0247, 0.0357],\n",
       "        [0.0221, 0.0361],\n",
       "        [0.0230, 0.0382],\n",
       "        [0.0242, 0.0322],\n",
       "        [0.0252, 0.0359],\n",
       "        [0.0199, 0.0339],\n",
       "        [0.0237, 0.0345],\n",
       "        [0.0253, 0.0358],\n",
       "        [0.0196, 0.0344],\n",
       "        [0.0199, 0.0335],\n",
       "        [0.0237, 0.0373],\n",
       "        [0.0185, 0.0349],\n",
       "        [0.0211, 0.0306],\n",
       "        [0.0234, 0.0327],\n",
       "        [0.0240, 0.0347],\n",
       "        [0.0197, 0.0355],\n",
       "        [0.0224, 0.0361],\n",
       "        [0.0200, 0.0331],\n",
       "        [0.0211, 0.0340],\n",
       "        [0.0252, 0.0345],\n",
       "        [0.0193, 0.0363],\n",
       "        [0.0160, 0.0196],\n",
       "        [0.0202, 0.0404],\n",
       "        [0.0220, 0.0401],\n",
       "        [0.0214, 0.0366],\n",
       "        [0.0199, 0.0340],\n",
       "        [0.0192, 0.0344],\n",
       "        [0.0207, 0.0330],\n",
       "        [0.0188, 0.0349],\n",
       "        [0.0214, 0.0303],\n",
       "        [0.0236, 0.0324],\n",
       "        [0.0187, 0.0353],\n",
       "        [0.0200, 0.0334],\n",
       "        [0.0207, 0.0414],\n",
       "        [0.0191, 0.0393],\n",
       "        [0.0162, 0.0385],\n",
       "        [0.0171, 0.0435],\n",
       "        [0.0208, 0.0351],\n",
       "        [0.0207, 0.0393],\n",
       "        [0.0212, 0.0371],\n",
       "        [0.0212, 0.0323],\n",
       "        [0.0243, 0.0333],\n",
       "        [0.0236, 0.0330],\n",
       "        [0.0185, 0.0405],\n",
       "        [0.0153, 0.0375],\n",
       "        [0.0217, 0.0370],\n",
       "        [0.0174, 0.0384],\n",
       "        [0.0192, 0.0387],\n",
       "        [0.0166, 0.0390],\n",
       "        [0.0174, 0.0380],\n",
       "        [0.0202, 0.0150],\n",
       "        [0.0260, 0.0337],\n",
       "        [0.0270, 0.0351],\n",
       "        [0.0220, 0.0327],\n",
       "        [0.0210, 0.0346],\n",
       "        [0.0266, 0.0343],\n",
       "        [0.0196, 0.0339],\n",
       "        [0.0226, 0.0383],\n",
       "        [0.0178, 0.0350],\n",
       "        [0.0215, 0.0323],\n",
       "        [0.0207, 0.0324],\n",
       "        [0.0204, 0.0384],\n",
       "        [0.0173, 0.0379],\n",
       "        [0.0210, 0.0401],\n",
       "        [0.0197, 0.0401],\n",
       "        [0.0197, 0.0404],\n",
       "        [0.0163, 0.0384],\n",
       "        [0.0171, 0.0434],\n",
       "        [0.0263, 0.0369],\n",
       "        [0.0211, 0.0330],\n",
       "        [0.0227, 0.0388],\n",
       "        [0.0221, 0.0367],\n",
       "        [0.0231, 0.0344],\n",
       "        [0.0218, 0.0376],\n",
       "        [0.0253, 0.0384],\n",
       "        [0.0268, 0.0369],\n",
       "        [0.0247, 0.0350],\n",
       "        [0.0203, 0.0329],\n",
       "        [0.0203, 0.0331],\n",
       "        [0.0248, 0.0366],\n",
       "        [0.0261, 0.0353],\n",
       "        [0.0167, 0.0371],\n",
       "        [0.0177, 0.0379],\n",
       "        [0.0185, 0.0381],\n",
       "        [0.0229, 0.0325],\n",
       "        [0.0226, 0.0356],\n",
       "        [0.0191, 0.0360],\n",
       "        [0.0195, 0.0407],\n",
       "        [0.0208, 0.0386],\n",
       "        [0.0185, 0.0366],\n",
       "        [0.0220, 0.0365],\n",
       "        [0.0176, 0.0386],\n",
       "        [0.0204, 0.0388],\n",
       "        [0.0204, 0.0385],\n",
       "        [0.0223, 0.0338],\n",
       "        [0.0214, 0.0320],\n",
       "        [0.0258, 0.0320],\n",
       "        [0.0260, 0.0324],\n",
       "        [0.0216, 0.0327],\n",
       "        [0.0165, 0.0189],\n",
       "        [0.0219, 0.0371],\n",
       "        [0.0222, 0.0399],\n",
       "        [0.0234, 0.0352],\n",
       "        [0.0207, 0.0365],\n",
       "        [0.0212, 0.0317],\n",
       "        [0.0214, 0.0355],\n",
       "        [0.0199, 0.0342],\n",
       "        [0.0191, 0.0344],\n",
       "        [0.0258, 0.0352],\n",
       "        [0.0192, 0.0354],\n",
       "        [0.0200, 0.0323],\n",
       "        [0.0196, 0.0374],\n",
       "        [0.0199, 0.0321],\n",
       "        [0.0237, 0.0327],\n",
       "        [0.0197, 0.0334],\n",
       "        [0.0195, 0.0369],\n",
       "        [0.0200, 0.0369],\n",
       "        [0.0230, 0.0349],\n",
       "        [0.0187, 0.0353],\n",
       "        [0.0220, 0.0353],\n",
       "        [0.0185, 0.0377],\n",
       "        [0.0207, 0.0303],\n",
       "        [0.0226, 0.0301],\n",
       "        [0.0252, 0.0313],\n",
       "        [0.0220, 0.0369],\n",
       "        [0.0219, 0.0351],\n",
       "        [0.0221, 0.0363],\n",
       "        [0.0199, 0.0366],\n",
       "        [0.0217, 0.0345],\n",
       "        [0.0162, 0.0379],\n",
       "        [0.0225, 0.0377],\n",
       "        [0.0193, 0.0326],\n",
       "        [0.0235, 0.0345],\n",
       "        [0.0225, 0.0362],\n",
       "        [0.0243, 0.0332],\n",
       "        [0.0236, 0.0345],\n",
       "        [0.0198, 0.0374],\n",
       "        [0.0172, 0.0372],\n",
       "        [0.0202, 0.0319],\n",
       "        [0.0261, 0.0341],\n",
       "        [0.0204, 0.0330],\n",
       "        [0.0178, 0.0370],\n",
       "        [0.0213, 0.0367],\n",
       "        [0.0185, 0.0348],\n",
       "        [0.0200, 0.0330],\n",
       "        [0.0251, 0.0384],\n",
       "        [0.0233, 0.0407],\n",
       "        [0.0231, 0.0309],\n",
       "        [0.0202, 0.0302],\n",
       "        [0.0270, 0.0310],\n",
       "        [0.0257, 0.0315],\n",
       "        [0.0227, 0.0317],\n",
       "        [0.0257, 0.0322],\n",
       "        [0.0251, 0.0347],\n",
       "        [0.0198, 0.0348],\n",
       "        [0.0209, 0.0353],\n",
       "        [0.0209, 0.0346],\n",
       "        [0.0170, 0.0372]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataListLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataListLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6900, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        data = batch[0]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "        loss = loss_op(out, data[\"context\"].y)\n",
    "        print(loss)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "train(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('syntax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86a73a47477ba0aeb5784a0601a09572162e340e9fb1f4748688670acf6653e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
