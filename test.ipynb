{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"exp/test_0\"\n",
    "# model_checkpoint = \"deepset/bert-base-uncased-squad2\"\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model_checkpoint, tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/squad_v2/raw/dev-v2.0.json\", \"r\") as source_file:\n",
    "    raw_data = json.load(source_file)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-uncased-squad2').to('cuda:1')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-uncased-squad2\")\n",
    "\n",
    "def get_answer(question, context):\n",
    "    inputs = tokenizer(question, context, max_length=384, padding=\"max_length\", truncation=\"only_second\", return_tensors=\"pt\").to(\"cuda:1\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    answer_start_index = outputs.start_logits.argmax()\n",
    "    answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    answer = tokenizer.decode(predict_answer_tokens)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = {}\n",
    "for article in tqdm(raw_data):\n",
    "        title = article[\"title\"]\n",
    "        paragraphs = article[\"paragraphs\"]\n",
    "        for paragraph in paragraphs:\n",
    "            context = paragraph[\"context\"]\n",
    "            qas = paragraph[\"qas\"]\n",
    "            for qa in qas:\n",
    "                qid = qa[\"id\"]\n",
    "                question = qa[\"question\"]\n",
    "                # answer = qa_pipeline(question=question, context=context, handle_impossible_answer=True)\n",
    "                # answer_dict[qid] = answer[\"answer\"]\n",
    "                answer = get_answer(question=question, context=context)\n",
    "                answer_dict[qid] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/squad_v2/processed/pred.json\", \"w\") as wf:\n",
    "    wf.write(json.dumps(answer_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python squad_eval.py ./data/squad_v2/raw/dev-v2.0.json ./data/squad_v2/processed/pred_squad.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.hg_parser import ConstituencyParser, ConstituencyNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:23:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689da61783df47c0bdc6ca1396e9e438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:23:01 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-11-29 16:23:01 INFO: Use device: gpu\n",
      "2022-11-29 16:23:01 INFO: Loading: tokenize\n",
      "2022-11-29 16:23:03 INFO: Loading: pos\n",
      "2022-11-29 16:23:04 INFO: Loading: constituency\n",
      "2022-11-29 16:23:04 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "cp = ConstituencyParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = cp.get_sentences(\"How are you doing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid, cid = 0, 100000\n",
    "\n",
    "def iterate_tree(root):\n",
    "    global tid, cid\n",
    "    if root.is_preterminal():\n",
    "        leaf_node = ConstituencyNode(cid=tid, label=root.label, text=root.leaf_labels(), lids=[tid], children=[])\n",
    "        tid += 1\n",
    "        return leaf_node\n",
    "    else:\n",
    "        child_nodes = list()\n",
    "        lids = list()\n",
    "        for child in root.children:\n",
    "            child_node = iterate_tree(child)\n",
    "            child_nodes += [child_node]\n",
    "            lids += child_node.lids\n",
    "\n",
    "        leaf_node = ConstituencyNode(cid=cid, label=root.label, text=root.leaf_labels(), lids=lids, children=child_nodes)\n",
    "        cid += 1\n",
    "        return leaf_node\n",
    "            \n",
    "root = iterate_tree(sentences[0].constituency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid: 100006 | label: ROOT | text: ['How', 'are', 'you', 'doing', 'today', '?'] | lids: [0, 1, 2, 3, 4, 5] | children: [100005] | answer: False\n"
     ]
    }
   ],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid: 100006 | label: ROOT | text: ['How', 'are', 'you', 'doing', 'today', '?'] | lids: [0, 1, 2, 3, 4, 5] | children: [100005] | answer: False\n",
      "cid: 100005 | label: SBARQ | text: ['How', 'are', 'you', 'doing', 'today', '?'] | lids: [0, 1, 2, 3, 4, 5] | children: [100000, 100004, 5] | answer: False\n",
      "cid: 100000 | label: WHADVP | text: ['How'] | lids: [0] | children: [0] | answer: False\n",
      "cid: 0 | label: WRB | text: ['How'] | lids: [0] | children: [] | answer: False\n",
      "cid: 100004 | label: SQ | text: ['are', 'you', 'doing', 'today'] | lids: [1, 2, 3, 4] | children: [1, 100001, 100003] | answer: False\n",
      "cid: 1 | label: VBP | text: ['are'] | lids: [1] | children: [] | answer: False\n",
      "cid: 100001 | label: NP | text: ['you'] | lids: [2] | children: [2] | answer: False\n",
      "cid: 2 | label: PRP | text: ['you'] | lids: [2] | children: [] | answer: False\n",
      "cid: 100003 | label: VP | text: ['doing', 'today'] | lids: [3, 4] | children: [3, 100002] | answer: False\n",
      "cid: 3 | label: VBG | text: ['doing'] | lids: [3] | children: [] | answer: False\n",
      "cid: 100002 | label: NP | text: ['today'] | lids: [4] | children: [4] | answer: False\n",
      "cid: 4 | label: NN | text: ['today'] | lids: [4] | children: [] | answer: False\n",
      "cid: 5 | label: . | text: ['?'] | lids: [5] | children: [] | answer: False\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def dfs(root):\n",
    "    print(root)\n",
    "    \n",
    "    for child in root.children:\n",
    "        dfs(child)\n",
    "    \n",
    "dfs(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('syntax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86a73a47477ba0aeb5784a0601a09572162e340e9fb1f4748688670acf6653e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
